{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Run\n",
    "\n",
    "This notebook loads the pre-trained TF binding prediction model, runs inference on the held-out test sequence dataset (such as `chr22_sequences.txt.gz`), loads the corresponding ground truth scores (such as `chr22_scores.txt.gz`), and calculates the Pearson's R correlation between predictions and ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data' # Replace here for the held-out test data directory\n",
    "SEQ_FILE = os.path.join(DATA_DIR, 'chr22_sequences.txt.gz') # Replace here for the held-out test data name\n",
    "SCORE_FILE = os.path.join(DATA_DIR, 'chr22_scores.txt.gz') # Ground truth scores file\n",
    "MODEL_WEIGHTS_FILE = 'lee-inhyeok-model.pth'\n",
    "\n",
    "# Model Hyperparameters\n",
    "NUM_CHANNELS = 32\n",
    "NUM_RES_BLOCKS = 3\n",
    "DROPOUT_RATE = 0.2\n",
    "KERNEL_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence):\n",
    "    \"\"\"Converts a DNA sequence string to a one-hot encoded tensor.\"\"\"\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    seq_len = len(sequence)\n",
    "    encoded = torch.zeros((4, seq_len), dtype=torch.float32)\n",
    "    for i, base in enumerate(sequence.upper()):\n",
    "        idx = mapping.get(base, -1)\n",
    "        if idx != -1:\n",
    "            encoded[idx, i] = 1.0\n",
    "    return encoded\n",
    "\n",
    "def calculate_pearsonr(preds, targets):\n",
    "    \"\"\"Calculates Pearson correlation between prediction and target tensors.\"\"\"\n",
    "    # Ensure inputs are tensors on CPU and flattened\n",
    "    preds_flat = preds.detach().cpu().numpy().flatten()\n",
    "    targets_flat = targets.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Remove NaNs\n",
    "    valid_indices = np.isfinite(preds_flat) & np.isfinite(targets_flat)\n",
    "    preds_flat = preds_flat[valid_indices]\n",
    "    targets_flat = targets_flat[valid_indices]\n",
    "\n",
    "    if len(preds_flat) < 2:\n",
    "        print(\"Warning: Not enough valid data points to calculate Pearson R.\")\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        r, p_value = pearsonr(preds_flat, targets_flat)\n",
    "        print(f\"Pearson R p-value: {p_value}\")\n",
    "        return r if np.isfinite(r) else 0.0\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating Pearson R: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block with LayerNorm.\"\"\"\n",
    "    def __init__(self, num_channels, kernel_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        norm_shape = [num_channels, 300]\n",
    "        self.conv1 = nn.Conv1d(num_channels, num_channels, kernel_size, stride=1, padding=kernel_size // 2, bias=False)\n",
    "        self.norm1 = nn.LayerNorm(norm_shape)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels, kernel_size, stride=1, padding=kernel_size // 2, bias=False)\n",
    "        self.norm2 = nn.LayerNorm(norm_shape)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out += identity\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "class BindingPredictorCNN(nn.Module):\n",
    "    def __init__(self, num_channels, num_blocks, kernel_size, dropout_rate):\n",
    "        super().__init__()\n",
    "        initial_norm_shape = [num_channels, 300]\n",
    "        self.initial_conv = nn.Conv1d(4, num_channels, kernel_size, stride=1, padding=kernel_size // 2, bias=False)\n",
    "        self.initial_norm = nn.LayerNorm(initial_norm_shape)\n",
    "        self.initial_relu = nn.ReLU()\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(num_channels, kernel_size, dropout_rate) for _ in range(num_blocks)])\n",
    "        self.final_conv = nn.Conv1d(num_channels, 1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_norm(x)\n",
    "        x = self.initial_relu(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model and weights...\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device (Apple Silicon GPU).\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device.\")\n",
    "\n",
    "model = BindingPredictorCNN(\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    num_blocks=NUM_RES_BLOCKS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_WEIGHTS_FILE, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    print(f\"Successfully loaded model weights from {MODEL_WEIGHTS_FILE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model weights file not found at {MODEL_WEIGHTS_FILE}. Cannot proceed.\")\n",
    "    # Optionally raise the error or exit\n",
    "    # raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Sequence and Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading sequence and score data...\")\n",
    "sequences_df = None\n",
    "scores_df = None\n",
    "try:\n",
    "    sequences_df = pd.read_csv(SEQ_FILE, sep=\"\\t\", compression='gzip')\n",
    "    scores_df = pd.read_csv(SCORE_FILE, sep=\"\\t\", compression='gzip')\n",
    "    print(f\"Loaded {len(sequences_df)} sequences and {len(scores_df.columns)} score vectors.\")\n",
    "    \n",
    "    # Basic check for consistency\n",
    "    if len(sequences_df) != len(scores_df.columns):\n",
    "        print(f\"Warning: Number of sequences ({len(sequences_df)}) does not match number of score columns ({len(scores_df.columns)}). Ensure they correspond correctly.\")\n",
    "        min_len = min(len(sequences_df), len(scores_df.columns))\n",
    "        sequences_df = sequences_df.iloc[:min_len]\n",
    "        scores_df = scores_df.iloc[:, :min_len]\n",
    "        print(f\"Proceeding with {min_len} sequence/score pairs.\")\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Data file not found. Ensure '{e.filename}' exists in '{DATA_DIR}'.\")\n",
    "    # Optionally raise the error or exit\n",
    "    # raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Input and Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing input and ground truth data...\")\n",
    "inputs_tensor = None\n",
    "ground_truth_tensor = None\n",
    "\n",
    "if sequences_df is not None and scores_df is not None:\n",
    "    # One-hot encode all sequences from the file\n",
    "    all_sequences = sequences_df['sequence'].tolist()\n",
    "    all_inputs_list = [one_hot_encode(seq) for seq in all_sequences]\n",
    "\n",
    "    # Prepare ground truth score tensors\n",
    "    all_score_tensors = [torch.tensor(scores_df[col].values, dtype=torch.float32) for col in scores_df.columns]\n",
    "\n",
    "    # Stack inputs and ground truth into single tensors\n",
    "    inputs_tensor = torch.stack(all_inputs_list).to(device)\n",
    "    ground_truth_tensor = torch.stack(all_score_tensors).to(device)\n",
    "\n",
    "    print(f\"Prepared {len(all_inputs_list)} inputs and corresponding ground truth scores.\")\n",
    "    print(f\"Input tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Ground truth tensor shape: {ground_truth_tensor.shape}\")\n",
    "else:\n",
    "    print(\"Skipping data preparation due to previous loading errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predict on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing inference on the test dataset...\")\n",
    "predictions = None\n",
    "if inputs_tensor is not None:\n",
    "    with torch.no_grad(): # Ensure gradients are not calculated\n",
    "        predictions = model(inputs_tensor)\n",
    "    print(\"Inference complete.\")\n",
    "else:\n",
    "    print(\"Skipping inference due to missing input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Pearson's R Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating Pearson's R correlation...\")\n",
    "if predictions is not None and ground_truth_tensor is not None:\n",
    "    # Ensure predictions and ground truth have the same shape for comparison\n",
    "    if predictions.shape == ground_truth_tensor.shape:\n",
    "        overall_pearson_r = calculate_pearsonr(predictions, ground_truth_tensor)\n",
    "        print(f\"\\nPearson's R score: {overall_pearson_r:.4f}\")\n",
    "    else:\n",
    "        print(f\"Error: Shape mismatch between predictions ({predictions.shape}) and ground truth ({ground_truth_tensor.shape}). Cannot calculate correlation.\")\n",
    "else:\n",
    "    print(\"Skipping correlation calculation due to missing predictions or ground truth data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
